# -*- coding: utf-8 -*-
"""test Main file _NN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17ked6FNXY8OgEtCgpqRts_dMCsdZZLlx
"""

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

df = pd.read_csv('kddcup99_csv.csv')
x = df.iloc[:, :-1].values
y = df.iloc[:, -1].values
df

df.dropna(inplace=True,axis=1)
df

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

# extract numerical attributes and scale it to have zero mean and unit variance  
cols = df.select_dtypes(include=['float64','int64']).columns
sc_df = scaler.fit_transform(df.select_dtypes(include=['float64','int64']))


# turn the result back to a dataframe
sc_df1 = pd.DataFrame(sc_df, columns = cols)

from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()

# extract categorical attributes from both training and test sets 
catdf1 = df.select_dtypes(include=['object']).copy()


# encode the categorical attributes
dfcat = catdf1.apply(encoder.fit_transform)


# separate target column from encoded data 
encdf = dfcat.drop(['label'], axis=1)
cat_ydf = dfcat[['label']].copy()

cat_ydf.dropna(inplace=True,axis=1)

# This is the numeric feature vector, as it goes to the neural net


# Convert to numpy - Classification
x_columns = cat_ydf.columns.drop('label')
x = cat_ydf[x_columns].values
dummies = pd.get_dummies(cat_ydf['label']) # Classification
outcomes = dummies.columns
num_classes = len(outcomes)
y = dummies.values

x.shape

y.shape

import pandas as pd
import io
import requests
import numpy as np
import os
from sklearn.model_selection import train_test_split
from sklearn import metrics
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation
from tensorflow.keras.callbacks import EarlyStopping

# Create a test/train split.  25% test
# Split into train/test
x_train, x_test, y_train, y_test = train_test_split(
    x, y, test_size=0.25, random_state=42)

# Create neural net
model = Sequential()
model.add(Dense(10, input_dim=x.shape[1], activation='relu'))
model.add(Dense(50, input_dim=x.shape[1], activation='relu'))
model.add(Dense(10, input_dim=x.shape[1], activation='relu'))
model.add(Dense(1, kernel_initializer='normal'))
model.add(Dense(y.shape[1],activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam')
monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, 
                        patience=5, verbose=1, mode='auto',
                           restore_best_weights=True)
import time
start_time = time.time() 
model.fit(x_train,y_train,validation_data=(x_test,y_test),
          callbacks=[monitor],verbose=2,epochs=1000)
end_time = time.time() 
print("NN_Training time: ", end_time-start_time)

start_time = time.time() 
y_test_pred = model.predict(x_train) 
end_time = time.time() 
print("NN_Testing time: ", end_time-start_time)

from sklearn import metrics
pred = model.predict(x_test)
pred = np.argmax(pred,axis=1)
y_eval = np.argmax(y_test,axis=1)
score = metrics.accuracy_score(y_eval, pred)
from sklearn.metrics import precision_score, f1_score, recall_score, classification_report,accuracy_score
print ("model_Accuracy:", accuracy_score(y_eval, pred))
print ("model_F1 score:", f1_score(y_eval, pred, average='weighted'))
print ("model_Recall:", recall_score(y_eval, pred, average='weighted'))
print ("model_Precision:", precision_score(y_eval, pred, average='weighted'))
print ("model_clasification:",classification_report(y_eval, pred))